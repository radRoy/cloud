# Download test data from: https://osf.io/tn4xj/

# PATH_TO_BEST_CHECKPOINT (a file path, pointing to "best_checkpoint.pytorch" file)
model_path: /home/dwalth/data/outputs/chpt-231130-0/best_checkpoint.pytorch

model:
  name: ResidualUNet3D  # originally: ResidualUNet3D
  # number of input channels to the model
  in_channels: 1
  # number of output channels
  out_channels: 1
  # determines the order of operators in a single layer (crg - Conv3d+ReLU+GroupNorm)
  layer_order: gcr
  # initial number of feature maps
  f_maps: 32
  # number of groups in the groupnorm
  num_groups: 8
  # apply element-wise nn.Sigmoid after the final 1x1x1 convolution, otherwise apply nn.Softmax
  final_sigmoid: true
predictor:
  name: 'StandardPredictor'
loaders:
  # save predictions to output_dir (PATH_TO_OUTPUT_DIR)
  output_dir: /home/dwalth/data/outputs/chpt-231212-10/  # /home/dwalth/data/outputs/test-230720-0/best_checkpoint.pytorch
  # batch dimension; if number of GPUs is N > 1, then a batch_size of N * batch_size will automatically be taken for DataParallel
  batch_size: 1
  # how many subprocesses to use for data loading
  num_workers: 8
  # test loaders configuration
  test:
    file_paths:
      - /home/dwalth/scratch/datasets/wolny_lightsheet_boundary/test/  # /home/dwalth/scratch/datasets/babb03/ct3/-crop-bicubic-scaled0.25/raw_RGB24-czyx-label_uint16/test/  # PATH_TO_TEST_DIR

    slice_builder:
      name: SliceBuilder
      
      # patch_shape:  # original: [80, 170, 170]
        # TBD: NOTE SHAPES & REASONING WHEN A SESSION WORKED: <session>: dataset07 resolution (all zyx): 125,1169,414. patch = <[z,y,x]>
      patch_shape: [64,128,128]
        # previously [64,896,160]
      
      # stride_shape:  # original: [40, 90, 90]
        # TBD: NOTE SHAPES & REASONING WHEN A SESSION WORKED: <session>: dataset07 resolution (all zyx): 125,1169,414. stride = <[z,y,x]>
      stride_shape: [32,96,96]
        # previously [32,128,80]
        # wolny: make sure that they overlap each other for averaging patches in the end.

      # DW: what worked previously (i.e., did not result in an error) (dataset01, singlechannel488, kidney):
      # image resolution is [90,217,332] (all images had same resolution, then (dataset01))
      #patch_shape: [45, 105, 165]
      #stride_shape: [25, 55, 85]  # wolny: make sure that they overlap each other for averaging patches in the end.

      # Thomas: Yes, same rules apply to test & train config, regarding patch & stride shapes.
      # DW: No, this turns out to be false. Using the same patch and stride shapes (& therefore same rules) for predict3dunet as I did for train3dunet results in an invalid patch shape error (torch.size ...).

    transformer:
      raw:
        - name: Standardize
        - name: ToTensor
          expand_dims: true
